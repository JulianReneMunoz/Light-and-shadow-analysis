<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8"/>
    <title>Light and Shadow</title>
    <!-- GOOGLE FONT -->
    <link href="https://fonts.googleapis.com/css?family=Titillium+Web" rel="stylesheet" />
    <!-- BOOTSTRAP 4 -->
    <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.1.0/css/bootstrap.min.css" integrity="sha384-9gVQ4dYFwwWSjIDZnLEWnxCjeSWFphJiwGPXr1jddIhOegiu1FwO5qRGvFXOdJZ4" crossorigin="anonymous">
    <!-- SCROOLL REVEAL JS LIBRARY CDN -->
    <script src="https://unpkg.com/scrollreveal/dist/scrollreveal.min.js"></script>
    <!-- CUSTOM CSS -->
    <link rel="stylesheet" href="css/main.css">
  </head>
  <body>

    <!-- NAVIGATION -->
    <nav class="navbar navbar-expand-lg navbar-light bg-light fixed-top">
      <a class="navbar-brand" href="#">Research: Estimation of the height of a shape within a 2D image from its shadow by means of Neural Networks</a>
      <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNavAltMarkup" aria-controls="navbarNavAltMarkup" aria-expanded="false" aria-label="Toggle navigation">
        <span class="navbar-toggler-icon"></span>
      </button>
      <div class="collapse navbar-collapse" id="navbarNavAltMarkup">
        <div class="navbar-nav ml-auto">
          <a class="nav-item nav-link" href="#header">Home</a>
          <a class="nav-item nav-link" href="#info-one">About</a>
          <a class="nav-item nav-link" href="#contact">Contact</a>
        </div>
      </div>
    </nav>

    <!-- SECTION -->
    <section id="header">
      <div class="container mt-5">
        <div class="row">
          <div class="col-md-6 col-sm-6">
            <div class="header-content-left">
              <img src="img/varios_forms.png" style="width: 100%;">
            </div>
          </div>
          <div class="col-md-6 col-sm-6">
            <div class="header-content-right">
              <h1 class="display-4">Research:</h1>
				<h2 class="text-justify">Introduction</h2>
              <p class="text-justify"> The proposed dataset was developed entirely for the purpose of meeting the requirements of the proposed model,
                and due to the lack of one that meets them. It consists of images of the shapes or objects, shadows and intensities, which for this
                research are a fundamental part and the essential resource to achieve the proposed objectives.</p>
              <p class="text-justify" >In addition, geometric objects have a common characteristic, which is that they are uniform in their edges as
                 well as in their structure and shadows. The latter can be processed in different models, convolutional neural network architectures,
                 with deep learning and using algorithms with which the experimentation process would be carried out, to determine the height and generate
                 the volume of the object from the shadow it casts.</p>
              <p class="text-justify" >One of the motivations in proposing this research is the possibility that with the information that is collected,
                processed and analyzed, through the use of neural networks, a deep learning model and a set of data can be obtained, which can be used to
                find the right combination of parameters for the shape from the shadows and light.</p>
              <p class="text-justify" >Hence the importance of this topic because it is expected
                to prove that it is possible to combine deep learning, a data set, the analysis of light and shadows for the development of an algorithm that
                in experimentation obtains optimal results. This being a theoretical-practical reference and a starting point to issues related to shadows,
                understanding that in these there is more information than can be perceived with the naked eye.</p>


              <a href="#" class="btn btn-outline-secondary header-btn btn-lg mt-2">Read More</a>
            </div>
          </div>
        </div>
      </div>
    </section>

    <section id="testimonial">
      <div class="container">
        <h1 class="display-4">Dataset</h1>
        <h2 class="text-justify">Construction of the dataset</h2>
        <p class="text-justify">
          In 2D digital images can be found different scenes, which contain elements such as textures, edges, shapes, colors, shadows, etc.,
          from which relevant information can be extracted and used in research through the implementation of shadow detection algorithms.
          This information is used to establish the relationship between the geometry of the object, the light source and the shadow area.
		  It is also understood that shadows are a source of relevant information at the level of shapes of surfaces or objects, allowing
          to locate areas of interest in an image, direction of the illumination source, geometry of the shape, among other characteristics
          (Kriegman, Belhumeur 1998).
        </p>

        <div class="header-content-left">
          <img src="img/AllFigures.png" style="width: 90%;">
        </div>
        <br>

        <p class="text-justify">
          These geometric properties of shadows are of special interest for this work, because they allow
          establishing perceivable relationships between shapes, shadows and illumination, according to the structure and height of the
          surface (Knill, Mamassian and Kersten 1997).
        </p>


        <div class="header-content-left">
          <img src="img/cilindro6_00011.jpg" style="width: 20%;">
          <img src="img/cubo5_00007.jpg" style="width: 20%;">
          <img src="img/DSC_0385-1.png" style="width: 20%;">
          <img src="img/Esferas de tamaños-1.png" style="width: 20%;">
        </div><br>
        <div class="header-content-left">
          <img src="img/esfera6_00046-1.png" style="width: 20%;">
          <img src="img/esfera6_00124-1.png" style="width: 20%;">
          <img src="img/DSC_0460-1.png" style="width: 20%;">
          <img src="img/DSC_0467-1.png" style="width: 20%;">
        </div>
        <br>
        <p class="text-justify">
          After reviewing the content of the Datasets, it is identified that they do not meet several of the requirements proposed here.
          Therefore, it is proposed to build the dataset according to the requirements, among them, that it can be scalable in the amount
          of data, different sizes of shapes and objects, being able to include new real photographs of geometric shapes with their shadows,
          including features that are essential to optimize the results. In addition, the images can be organized and/or classified
          in folders according to the most relevant features, which is a way to properly structure the dataset.
        </p>


        <div class="header-content-left">
          <img src="img/dataset3-1.png" style="width: 40%">
          <img src="img/image2.png" style="width: 37%">
        </div>


        <p class="text-justify"><br> </p>
        <h2 class="text-justify">Diagram: Dataset with geometric figures</h2>

        <div class="header-content-left">
          <img src="img/Metodology-10.png" style="width: 90%;">
        </div><br>

        <ul>
          <li><p class="text-justify">Construction of a photographic dataset with RGB images (3 channels).</p></li>
          <li><p class="text-justify">Dimmable white light led lamp, a potentiometer and a matte white surface.</p></li>
          <li><p class="text-justify">Fixed camera at 45 and 50 units and 45 degree tilt angle.</p></li>
          <li><p class="text-justify">Convolutional Neural Network, supervised learning.</p></li>
          <li><p class="text-justify">Geometric shapes (cubes, spheres and cylinders) with different
            heights and also including some of synthetic material are produced in wood.</p></li>
          <li><p class="text-justify">Photographs were taken of geometric shapes with uniform edges and shapes,
            initially of cubes, spheres and cylinders. The environment for taking the photographs was controlled
            both in the source of illumination and in the type of geometric shape.</p></li>
          <li><p class="text-justify">The images were preprocessed to have a dimension of 800 by 600 pixels and three RGB channels (Red, Green, Blue).</p></li>
          <li><p class="text-justify">The Dataset has 4,500 images (spheres, cubes and cylinders) of 800 by 600 pixels.</p></li>
        </ul>

      </div>
    </section>

    <section id="info-one">
      <div class="container">
        <div class="row mt-5">
          <div class="col-md-6">
            <div class="info-left">

              <div class="col-md-6">
                <h2>Contact</h2>
                <ul>
                  <li><p>Julian Rene Munoz B</p></li>
                  <li><p>Telephone/Cellular: (57) 3108987728, 3137063049 (Colombia)</p></li>
                  <li><p>Email: jmb@unicauca.edu.co, juremu82@gmail.com, jrmb82@hotmail.com</p></li>
                  <li><a rel="author" href="https://www.linkedin.com/in/juli%C3%A1n-ren%C3%A9-mu%C3%B1oz-burbano-65827064/">LinkedIn</a></li>
                </ul>
              </div>


            </div>
          </div>
          <div class="col-md-6 my-auto">
            <div class="info-right">
              <h2>Tools used:</h2>
              <p class="text-justify">Imagej:
                </p>
              <p>Official download page:</p>
              <ul>
                <li><a rel="author" href="https://imagej.nih.gov/ij/download.html">Download Imagej</a></li>
              </ul>
              <p>For more information:</p>
              <ul>
                <li><a rel="author" href="https://imagej.nih.gov/ij/docs/index.html">User Guide Imagej</a></li>
              </ul>
              <br>


              <p class="text-justify">Anaconda:
                Tensorflow, keras, etc. </p>

              <p>Official download page:</p>
              <ul>
                <li><a rel="author" href="https://www.anaconda.com/">Download Anaconda</a></li>
              </ul>
              <p>For more information:</p>
              <ul>
                <li><a rel="author" href="https://docs.anaconda.com/navigator/index.html">User Guide Anaconda</a></li>
              </ul>
              <br>

              <p class="text-justify">MatLab:
                </p>
              <p>Official download page:</p>
              <ul>
                <li><a rel="author" href="https://es.mathworks.com/">Download Matlab</a></li>
              </ul>
              <p>For more information:</p>
              <ul>
                <li><a rel="author" href="https://es.mathworks.com/help/matlab/index.html?s_tid=CRUX_lftnav">User Guide MatLab</a></li>
              </ul>

              <a href="#" class="btn btn-outline-secondary btn-lg">Read More</a>
            </div>
          </div>
        </div>
      </div>
    </section>

    <section id="info-two">
      <div class="container">
        <div class="row my-5">
          <div class="col-md-6">

            <h2>About</h2>

            <ul>
              <li><p>Postgraduate Student at the University of Cauca</p></li>
              <li><p>University Professor and Researcher</p></li>
              <li><p>Faculty of Electronic Engineering and Telecommunications</p></li>
              <li><p>Department of Telecommunications</p></li>
              <li><p>R&D Group in New Technologies in Telecommunications - GNTT</p></li>
              <li><p>Line of research: Signals and Telecommunications Systems</p></li>
            </ul>
          </div>

          <div class="col-md-6">
            <h2>Bibliographic References</h2>
            <p class="text-justify">The following are some of the references:</p>
            <p class="text-justify">Panagopoulos, A., Hadap, S. and Samaras, D. (2013) ‘Reconstructing shape from dictionaries of shading primitives’, Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics), 7727 LNCS (PART 4), pp. 80–94.</p>
            <p class="text-justify">Bouguett, J., Webert, M. and Peronat, P. (1999a) ‘What do planar shadows tell about scene geometry’, IEEE.</p>
            <p class="text-justify">Varol, A. et al. (2012) ‘Monocular 3D reconstruction of locally textured surfaces’, IEEE Transactions on Pattern Analysis and Machine Intelligence, 34(6), pp. 1118–1130. DOI: 10.1109/TPAMI.2011.196.</p>
            <p class="text-justify">Forsyth, D. and Zisserman, A. (1989) ‘Mutual illumination’, (v), pp. 466–473. DOI: 10.1109/cvpr.1989.37889 .</p>
            <p class="text-justify">Vicente, T. F. Y., Yu, C.-P. and Samaras, D. (2014) ‘Single Image Shadow Detection Using Multiple Cues in a Supermodular MRF’, pp. 126.1-126.11. DOI: 10.5244/c.27.126.</p>
            <p class="text-justify">Cammarano, M. and Hanrahan, P. (2002) ‘Shadow Silhouette Maps’, ACM Transacciones de ACM en gráficos, 22, pp. 521–526.</p>
            <p class="text-justify">Daum, M. et al. (1998) ‘On 3-D Surface Reconstruction Using Shape from Shadows’, IEEE Con- ference on Computer Vision and Pattern Recognition (CVPR), pp. 1–8.</p>

          </div>
        </div>
      </div>
    </section>

    <footer id="contact">
      <div class="container">
        <div class="row">
          <div class="col-md-5">
            <form class="card mt-4">
              <div class="card-body">
                <div class="form-group">
                  <input type="text" class="form-control" placeholder="Name">
                </div>
                <div class="form-group">
                  <input type="text" class="form-control" placeholder="Email">
                </div>
                <div class="form-group">
                  <textarea cols="30" rows="10" placeholder="Message" class="form-control"></textarea>
                </div>
                <button class="btn btn-outline-secondary btn-block">
                  Send
                </button>
              </div>
            </form>
          </div>
        </div>
      </div>
      <br><br><br><br>
    </footer>

    <!-- SCRIPTS -->
    <script src="https://code.jquery.com/jquery-3.3.1.slim.min.js" integrity="sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.0/umd/popper.min.js" integrity="sha384-cs/chFZiN24E4KMATLdqdvsezGxaGsi4hLGOzlXwp5UZB1LY//20VyM2taTB4QvJ" crossorigin="anonymous"></script>
    <script src="https://stackpath.bootstrapcdn.com/bootstrap/4.1.0/js/bootstrap.min.js" integrity="sha384-uefMccjFJAIv6A+rW+L4AHf99KvxDjWSu1z9VI8SKNVmz4sk7buKt/6v9KI65qnm" crossorigin="anonymous"></script>
    <!-- SCROOLL REVEAL SCRIPT -->
    <script>
      window.sr = ScrollReveal();

    sr.reveal('.navbar', {
      duration: 2000,
      origin: 'bottom'
    });

    sr.reveal('.header-content-left', {
      duration: 2000,
      origin: 'top',
      distance: '300px'
    });

    sr.reveal('.header-content-right', {
      duration: 2000,
      origin: 'right',
      distance: '300px'
    });

    sr.reveal('.header-btn', {
      duration: 2000,
      delay: 1000, 
      origin: 'bottom'
    });

    sr.reveal('#testimonial div', {
      duration: 2000,
      origin: 'left',
      distance: '300px',
      viewFactor: 0.2
    });

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
      anchor.addEventListener('click', function (e) {
        e.preventDefault();

        document.querySelector(this.getAttribute('href')).scrollIntoView({
          behavior: 'smooth'
        });
      });
    });
    </script>
  </body>
</html>
